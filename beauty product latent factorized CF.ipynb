{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Factorized Collaborative Filter with Mini-Batch SGD on Amazon Beauty Product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns; sns.set(style=\"white\", color_codes=True)\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df_original = getDF('Beauty_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>overall</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1YJEY40YUW4SE</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>1391040000</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>01 30, 2014</td>\n",
       "      <td>Very oily and creamy. Not at all what I expect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A60XNB876KYML</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Jessica H.</td>\n",
       "      <td>1397779200</td>\n",
       "      <td>OK Palette!</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>04 18, 2014</td>\n",
       "      <td>This palette was a decent price and I was look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3G6XNM240RMWA</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Karen</td>\n",
       "      <td>1378425600</td>\n",
       "      <td>great quality</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>09 6, 2013</td>\n",
       "      <td>The texture of this concealer pallet is fantas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1PQFP6SAJ6D80</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Norah</td>\n",
       "      <td>1386460800</td>\n",
       "      <td>Do not work on my face</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>12 8, 2013</td>\n",
       "      <td>I really can't tell what exactly this thing is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A38FVHZTNQ271F</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Nova Amor</td>\n",
       "      <td>1382140800</td>\n",
       "      <td>It's okay.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>10 19, 2013</td>\n",
       "      <td>It was a little smaller than I expected, but t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin reviewerName  unixReviewTime  \\\n",
       "0  A1YJEY40YUW4SE  7806397051       Andrea      1391040000   \n",
       "1   A60XNB876KYML  7806397051   Jessica H.      1397779200   \n",
       "2  A3G6XNM240RMWA  7806397051        Karen      1378425600   \n",
       "3  A1PQFP6SAJ6D80  7806397051        Norah      1386460800   \n",
       "4  A38FVHZTNQ271F  7806397051    Nova Amor      1382140800   \n",
       "\n",
       "                  summary  overall helpful   reviewTime  \\\n",
       "0  Don't waste your money      1.0  [3, 4]  01 30, 2014   \n",
       "1             OK Palette!      3.0  [1, 1]  04 18, 2014   \n",
       "2           great quality      4.0  [0, 1]   09 6, 2013   \n",
       "3  Do not work on my face      2.0  [2, 2]   12 8, 2013   \n",
       "4              It's okay.      3.0  [0, 0]  10 19, 2013   \n",
       "\n",
       "                                          reviewText  \n",
       "0  Very oily and creamy. Not at all what I expect...  \n",
       "1  This palette was a decent price and I was look...  \n",
       "2  The texture of this concealer pallet is fantas...  \n",
       "3  I really can't tell what exactly this thing is...  \n",
       "4  It was a little smaller than I expected, but t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=copy.deepcopy(df_original)\n",
    "df['unixReviewTime']=pd.to_datetime(df['unixReviewTime'],unit='s')\n",
    "df.drop(['reviewTime'],axis=1,inplace=True)\n",
    "# set unique ID for each review\n",
    "df['ReviewID']=df.index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Distribution of Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAFgCAYAAACmDI9oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eb54320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.hist(df['overall'], bins=[0.9, 1.1, 1.9, 2.1, 2.9, 3.1, 3.9, 4.1, 4.9, 5.1])\n",
    "ax.set_xlabel('product rating', fontsize=15)\n",
    "\n",
    "# mean ratings from each user\n",
    "mean_rating_of_user = df.groupby('reviewerID').apply(lambda x: x['overall'].mean())\n",
    "ax = fig.add_subplot(122)\n",
    "ax.hist(mean_rating_of_user)\n",
    "ax.set_xlabel('mean rating given by each user', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings on items are severely left-skewed. Normalization is required both reviewer-wisely and item-wisely when training the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Number Of Reviewer and Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22363 users\n",
      "12101 items\n"
     ]
    }
   ],
   "source": [
    "n_users = df.reviewerID.unique().shape[0]\n",
    "n_items = df.asin.unique().shape[0]\n",
    "print (str(n_users) + ' users')\n",
    "print (str(n_items) + ' items')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse ID to Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step maps all asin and revierID in strings to numerical ID, which would be applied as position indexs of the rating matrixs with row as the number of reviewers times the columns as the number of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(['reviewerID', 'asin'], ascending = [True, True])\n",
    "df.asin=pd.core.categorical.Categorical(df.asin)\n",
    "df['asin_id']=df.asin.cat.codes\n",
    "df.reviewerID=pd.core.categorical.Categorical(df.reviewerID)\n",
    "df['reviewer_ID']=df.reviewerID.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewer  22363\n",
      "item  12101\n"
     ]
    }
   ],
   "source": [
    "#check for the output of transformation to category\n",
    "print (\"reviewer \",pd.DataFrame(df.groupby(['reviewer_ID'])['reviewerID'].nunique()).sort_values(['reviewerID'],ascending=False).shape[0])\n",
    "print (\"item \", pd.DataFrame(df.groupby(['asin_id'])['asin'].nunique()).sort_values(['asin'],ascending=False).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df_ratings=df[['reviewer_ID','asin_id','overall']]\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "\n",
    "for row in df_ratings.itertuples():\n",
    "    #print (row[1],row[2],row[3])\n",
    "    ratings[row[1], row[2]] = row[3]\n",
    "    \n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.07%\n"
     ]
    }
   ],
   "source": [
    "#sparsity check\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity = (sparsity/(ratings.shape[0] * ratings.shape[1]))*100\n",
    "print ('Sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Distribution on Number of Items Rated by Users and Items Rated by Number of Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_rated_items=ratings.nonzero()[0]\n",
    "min_rated_items_collection={}\n",
    "for i in min_rated_items:\n",
    "    if i in min_rated_items_collection:\n",
    "        min_rated_items_collection[i]=min_rated_items_collection[i]+1\n",
    "    else:\n",
    "        min_rated_items_collection[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User rated  204 items at the most\n",
      "User rated  5 items at the least\n"
     ]
    }
   ],
   "source": [
    "user_rate_count=sorted(min_rated_items_collection.items(),key=lambda x:x[1])\n",
    "print ('User rated ',user_rate_count[-1][1], 'items at the most')\n",
    "print ('User rated ',user_rate_count[0][1], 'items at the least')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_rate_by_users=ratings.nonzero()[1]\n",
    "min_rate_by_users_collection={}\n",
    "for i in min_rate_by_users:\n",
    "    if i in min_rate_by_users_collection:\n",
    "        min_rate_by_users_collection[i]=min_rate_by_users_collection[i]+1\n",
    "    else:\n",
    "        min_rate_by_users_collection[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item rated by  431  sers at the most\n",
      "Item rated by  5  users at the least\n"
     ]
    }
   ],
   "source": [
    "item_rate_count=sorted(min_rate_by_users_collection.items(),key=lambda x:x[1])\n",
    "print ('Item rated by ',item_rate_count[-1][1], ' sers at the most')\n",
    "print ('Item rated by ',item_rate_count[0][1], ' users at the least')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set-up bins\n",
    "count_bin=np.linspace(10,100,10).tolist()\n",
    "count_bin.extend([5,300,500])\n",
    "array_rate_count=np.array(count_bin)\n",
    "array_rate_count=np.sort(array_rate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated_items_cat</th>\n",
       "      <th>userID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(, 5]</td>\n",
       "      <td>7162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10, 20]</td>\n",
       "      <td>3106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(100, 300]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(20, 30]</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(30, 40]</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>10959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(50, 60]</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(60, 70]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(70, 80]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(80, 90]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(90, 100]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated_items_cat  userID\n",
       "0            (, 5]    7162\n",
       "1         (10, 20]    3106\n",
       "2       (100, 300]      17\n",
       "3         (20, 30]     655\n",
       "4         (30, 40]     231\n",
       "5         (40, 50]      97\n",
       "6          (5, 10]   10959\n",
       "7         (50, 60]      62\n",
       "8         (60, 70]      23\n",
       "9         (70, 80]      26\n",
       "10        (80, 90]      14\n",
       "11       (90, 100]      11"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the user-rated item number distribution table\n",
    "def to_category(row,colname='rated_items',cate=array_rate_count):\n",
    "    first_arg=np.where(cate>=row[colname])[0][0]\n",
    "    if first_arg!=0:\n",
    "        return \"(\"+str(int(cate[first_arg-1]))+\", \"+str(int(cate[first_arg]))+\"]\", cate[first_arg]\n",
    "    else:\n",
    "        return \"(, \"+str(int(cate[first_arg]))+\"]\", cate[first_arg]\n",
    "\n",
    "item_count=pd.DataFrame.from_dict(min_rated_items_collection,orient='index')\\\n",
    ".reset_index().rename(columns={'index':'userID',0: 'rated_items'})\n",
    "item_count['rated_items_cat'],item_count['rated_items_num']=zip(*item_count\\\n",
    "                                                                .apply(to_category,cate=array_rate_count,axis=1))\n",
    "pd.DataFrame(item_count.groupby(['rated_items_cat'])['userID'].count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6QGGf6S1CDDX5IaZPhLUoP+PwZJjcy+WaNNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1110a3b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(item_count['rated_items_num'],array_rate_count)\n",
    "plt.title('number of items rated by each users', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated_by_user_cat</th>\n",
       "      <th>itemID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(, 5]</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10, 20]</td>\n",
       "      <td>2632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(100, 300]</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(20, 30]</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(30, 40]</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(300, 500]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>5031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(50, 60]</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(60, 70]</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(70, 80]</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(80, 90]</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(90, 100]</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated_by_user_cat  itemID\n",
       "0              (, 5]    2181\n",
       "1           (10, 20]    2632\n",
       "2         (100, 300]     159\n",
       "3           (20, 30]     870\n",
       "4           (30, 40]     422\n",
       "5         (300, 500]      10\n",
       "6           (40, 50]     240\n",
       "7            (5, 10]    5031\n",
       "8           (50, 60]     181\n",
       "9           (60, 70]     138\n",
       "10          (70, 80]      89\n",
       "11          (80, 90]      80\n",
       "12         (90, 100]      68"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the item rated by the number of users distribution table\n",
    "user_count=pd.DataFrame.from_dict(min_rate_by_users_collection,orient='index')\\\n",
    ".reset_index().rename(columns={'index':'itemID',0: 'rated_by_users'})\n",
    "user_count['rated_by_user_cat'],user_count['rated_by_user_num']=zip(*user_count.apply(to_category,colname='rated_by_users',cate=array_rate_count,axis=1))\n",
    "pd.DataFrame(user_count.groupby(['rated_by_user_cat'])['itemID'].count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1110a3fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(user_count['rated_by_user_num'],array_rate_count)\n",
    "plt.title('each item rated by X number of users', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Sparsity With N-Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "32% users rated only 5 items and 49% users rated 6 to 10 items. In this notebook, 8 is selected as the threshold for the items and users, i.e. each user should rated at least 8 items and each item should be rated by at least 8 users. Meanwhile, the map between the position index before and after the N-core transformaiton are kept to ensure the traceability of prediction result later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify N-core to add the map between new position to old position\n",
    "def apply_Ncore(ratings, N_core):\n",
    "    n_users = ratings.shape[0]\n",
    "    n_items = ratings.shape[1]\n",
    "    items_id = [x for x in range(n_items) if len(ratings[:, x].nonzero()[0]) >= N_core]\n",
    "    ratings = ratings[:, items_id]\n",
    "    # map the new items position to the old\n",
    "    item_link=list(zip(items_id,range(ratings.shape[1])))\n",
    "    users_id = [x for x in range(n_users) if len(ratings[x, :].nonzero()[0]) >= N_core]\n",
    "    # map the new user posistion to the old\n",
    "    ratings = ratings[users_id, :]\n",
    "    user_link=list(zip(users_id,range(ratings.shape[0])))\n",
    "    return ratings,item_link,user_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_Ncore,items_link_Ncore,users_link_Ncore = apply_Ncore(ratings, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying the 10-core, there are 6172 users left\n",
      "After applying the 10-core, there are 7129 items left\n",
      "Sparsity: 0.20%\n"
     ]
    }
   ],
   "source": [
    "print(\"After applying the 10-core, there are\", ratings_Ncore.shape[0], \"users left\")\n",
    "print(\"After applying the 10-core, there are\", ratings_Ncore.shape[1], \"items left\")\n",
    "sparsity = float(len(ratings_Ncore.nonzero()[0]))\n",
    "sparsity = (sparsity/(ratings_Ncore.shape[0] * ratings_Ncore.shape[1]))*100\n",
    "print ('Sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map User/Item Position Back To asin (item ID) and reviewerID (user ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>helpful</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>ReviewID</th>\n",
       "      <th>asin_id</th>\n",
       "      <th>reviewer_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145572</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B007IY97U0</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>Sarah Hale</td>\n",
       "      <td>Good quality wig, but the blonde is much more ...</td>\n",
       "      <td>145573</td>\n",
       "      <td>9449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152551</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>( After waiting over a month to receive this w...</td>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00870XLDS</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>Sarah Hale</td>\n",
       "      <td>Very thin and not as long as the photos :( Aft...</td>\n",
       "      <td>152552</td>\n",
       "      <td>9839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155883</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>( After waiting over a month to receive this w...</td>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B008MIRO88</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>Sarah Hale</td>\n",
       "      <td>Very thin and not as long as the photos :( Aft...</td>\n",
       "      <td>155884</td>\n",
       "      <td>10076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178477</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a great quality wig</td>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00BQYYMN0</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>Sarah Hale</td>\n",
       "      <td>This is a great quality wig, however it is a m...</td>\n",
       "      <td>178478</td>\n",
       "      <td>11155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188781</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is my absolute favorite wig! I have purch...</td>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00GRTQBTM</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>Sarah Hale</td>\n",
       "      <td>This is my absolute favorite wig! I have purch...</td>\n",
       "      <td>188782</td>\n",
       "      <td>11752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall helpful                                            summary  \\\n",
       "145572      3.0  [0, 0]                                        Three Stars   \n",
       "152551      2.0  [0, 0]  ( After waiting over a month to receive this w...   \n",
       "155883      1.0  [0, 0]  ( After waiting over a month to receive this w...   \n",
       "178477      3.0  [0, 0]                        This is a great quality wig   \n",
       "188781      5.0  [0, 0]  This is my absolute favorite wig! I have purch...   \n",
       "\n",
       "                   reviewerID        asin unixReviewTime reviewerName  \\\n",
       "145572  A00414041RD0BXM6WK0GX  B007IY97U0     2014-07-14   Sarah Hale   \n",
       "152551  A00414041RD0BXM6WK0GX  B00870XLDS     2014-07-14   Sarah Hale   \n",
       "155883  A00414041RD0BXM6WK0GX  B008MIRO88     2014-07-14   Sarah Hale   \n",
       "178477  A00414041RD0BXM6WK0GX  B00BQYYMN0     2014-07-14   Sarah Hale   \n",
       "188781  A00414041RD0BXM6WK0GX  B00GRTQBTM     2014-07-14   Sarah Hale   \n",
       "\n",
       "                                               reviewText  ReviewID  asin_id  \\\n",
       "145572  Good quality wig, but the blonde is much more ...    145573     9449   \n",
       "152551  Very thin and not as long as the photos :( Aft...    152552     9839   \n",
       "155883  Very thin and not as long as the photos :( Aft...    155884    10076   \n",
       "178477  This is a great quality wig, however it is a m...    178478    11155   \n",
       "188781  This is my absolute favorite wig! I have purch...    188782    11752   \n",
       "\n",
       "        reviewer_ID  \n",
       "145572            0  \n",
       "152551            0  \n",
       "155883            0  \n",
       "178477            0  \n",
       "188781            0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['reviewerID_Ncore']=df['reviewer_ID'].map(dict(users_link_Ncore))\n",
    "df['asinID_Ncore']=df['asin_id'].map(dict(items_link_Ncore))\n",
    "item_map_afterNcore=df[['asinID_Ncore','asin']].drop_duplicates(keep='first')\n",
    "user_map_afterNcore=df[['reviewerID_Ncore','reviewerID']].drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID_Ncore</th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22693</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A03364251DGXSGA9PSR99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID_Ncore             reviewerID\n",
       "22693               1.0  A03364251DGXSGA9PSR99"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_map_afterNcore.loc[user_map_afterNcore['reviewerID_Ncore']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewer_ID</th>\n",
       "      <th>reviewerID_Ncore</th>\n",
       "      <th>asin_id</th>\n",
       "      <th>asinID_Ncore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B00008MOQE</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>184</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B0001TOH8G</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>359</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11638</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B0007W1R58</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>687</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42136</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B0012UEJ1S</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2846</td>\n",
       "      <td>1644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66990</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B001YTD3G4</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4562</td>\n",
       "      <td>2622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92722</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B003OIPJZ6</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6250</td>\n",
       "      <td>3599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93742</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B003RF82UK</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6310</td>\n",
       "      <td>3636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103137</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B0048KSGZO</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6902</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103757</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B004AGM47C</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6943</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104465</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B004BCX8B6</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6992</td>\n",
       "      <td>4056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106531</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B004DIUWAI</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7116</td>\n",
       "      <td>4134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122013</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B005BDO4TY</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8121</td>\n",
       "      <td>4701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127276</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B005OU2Y1E</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138692</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B006OHM542</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9030</td>\n",
       "      <td>5239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154090</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B008CEDY5O</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9946</td>\n",
       "      <td>5770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164953</th>\n",
       "      <td>A099766128UI0NCS98N1E</td>\n",
       "      <td>B009YVCSYM</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10544</td>\n",
       "      <td>6127.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   reviewerID        asin  reviewer_ID  reviewerID_Ncore  \\\n",
       "3539    A099766128UI0NCS98N1E  B00008MOQE           29               4.0   \n",
       "6806    A099766128UI0NCS98N1E  B0001TOH8G           29               4.0   \n",
       "11638   A099766128UI0NCS98N1E  B0007W1R58           29               4.0   \n",
       "42136   A099766128UI0NCS98N1E  B0012UEJ1S           29               4.0   \n",
       "66990   A099766128UI0NCS98N1E  B001YTD3G4           29               4.0   \n",
       "92722   A099766128UI0NCS98N1E  B003OIPJZ6           29               4.0   \n",
       "93742   A099766128UI0NCS98N1E  B003RF82UK           29               4.0   \n",
       "103137  A099766128UI0NCS98N1E  B0048KSGZO           29               4.0   \n",
       "103757  A099766128UI0NCS98N1E  B004AGM47C           29               4.0   \n",
       "104465  A099766128UI0NCS98N1E  B004BCX8B6           29               4.0   \n",
       "106531  A099766128UI0NCS98N1E  B004DIUWAI           29               4.0   \n",
       "122013  A099766128UI0NCS98N1E  B005BDO4TY           29               4.0   \n",
       "127276  A099766128UI0NCS98N1E  B005OU2Y1E           29               4.0   \n",
       "138692  A099766128UI0NCS98N1E  B006OHM542           29               4.0   \n",
       "154090  A099766128UI0NCS98N1E  B008CEDY5O           29               4.0   \n",
       "164953  A099766128UI0NCS98N1E  B009YVCSYM           29               4.0   \n",
       "\n",
       "        asin_id  asinID_Ncore  \n",
       "3539        184         123.0  \n",
       "6806        359         237.0  \n",
       "11638       687         440.0  \n",
       "42136      2846        1644.0  \n",
       "66990      4562        2622.0  \n",
       "92722      6250        3599.0  \n",
       "93742      6310        3636.0  \n",
       "103137     6902        4001.0  \n",
       "103757     6943           NaN  \n",
       "104465     6992        4056.0  \n",
       "106531     7116        4134.0  \n",
       "122013     8121        4701.0  \n",
       "127276     8470           NaN  \n",
       "138692     9030        5239.0  \n",
       "154090     9946        5770.0  \n",
       "164953    10544        6127.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for whether the item id is linked back correctly to asin\n",
    "df.loc[df['reviewerID']=='A099766128UI0NCS98N1E',['reviewerID','asin','reviewer_ID','reviewerID_Ncore','asin_id','asinID_Ncore']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different from other entry-wise training test spliting, we split the data set by poping out N items bought by each users in the 8-core matrix into a test set and keep the rest in the training set. This training-test split increased the sparsity of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split_userwise(ratings,num_test=5):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    nonzero_id=np.transpose(np.array([ratings.nonzero()[0].tolist(),ratings.nonzero()[1].tolist()]))\n",
    "    index=pd.DataFrame(nonzero_id,columns=['row','col'])\n",
    "    gps =index.groupby(['row'])\n",
    "    randx = lambda obj: obj.loc[np.random.choice(obj.index, num_test, False),:]\n",
    "    test_ratings=gps.apply(randx).values.transpose()\n",
    "    test_ratings_row=test_ratings[0].tolist()\n",
    "    test_ratings_col=test_ratings[1].tolist()\n",
    "    train[test_ratings_row,test_ratings_col] = 0.\n",
    "    test[test_ratings_row,test_ratings_col] = ratings[test_ratings_row,test_ratings_col]   \n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_dimension:  (6172, 7129)\n",
      "test dimension:  (6172, 7129)\n"
     ]
    }
   ],
   "source": [
    "train_Ncore_user, test_Ncore_user = train_test_split_userwise(ratings_Ncore,num_test=3)\n",
    "# check whether the test dataset has the same shape as the training\n",
    "print('training_dimension: ', train_Ncore_user.shape)\n",
    "print('test dimension: ',test_Ncore_user.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each user has his/her bias on ratings. Some users tend to give an average rating higher than 3 while others might give an average lower than 3, vice versus for the item rated by users. Thus, the traing and test sets need be normalized if there is no user or item bias adjustment terms in the modeling class. Later on, at the stage of comparing the predicted ratings with the test set and calculate the Mean Square Errors, we should also subtract the normalized test set values from the prediciton trained by normalized training set and deduct the original test set ratings fom the prediction trained based on the training set without normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user-wise\n",
    "def normalize_userwise(train,test):\n",
    "    user=0\n",
    "    train_new=copy.deepcopy(train)\n",
    "    test_new=copy.deepcopy(test)\n",
    "    for i in range(train_new.shape[0]):\n",
    "        items=np.nonzero(train_new[i,:])[0].tolist()\n",
    "        user_avg=np.sum(train_new[i,items])/len(items)\n",
    "        items_test=np.nonzero(test_new[i,:])[0].tolist()\n",
    "        train_new[i,items]=(train_new[i,items]-user_avg)\n",
    "        test_new[i,items_test]=(test_new[i,items_test]-user_avg)\n",
    "    return train_new, test_new\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Ncore_user_normalized,test_Ncore_user_normalized=normalize_userwise(train_Ncore_user,test_Ncore_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average ratings for user 0 in training after normalization:  1.7763568394e-15\n",
      "average ratings for user 0 in test after normalization:  2.3\n"
     ]
    }
   ],
   "source": [
    "# check for the output of normaization\n",
    "# user for 0 in training set\n",
    "user_0_trainting_sum=np.sum(train_Ncore_user_normalized[1,[x[1] for x in \\\n",
    "                                       list(zip(np.nonzero(train_Ncore_user_normalized)[0],\\\n",
    "                                            np.nonzero(train_Ncore_user_normalized)[1])) if x[0]==1]])\n",
    "print ('average ratings for user 0 in training after normalization: ', user_0_trainting_sum)\n",
    "\n",
    "# user for 0 in test set\n",
    "user_0_test_sum=np.sum(test_Ncore_user_normalized[1,[x[1] for x in \\\n",
    "                                       list(zip(np.nonzero(test_Ncore_user_normalized)[0],\\\n",
    "                                            np.nonzero(test_Ncore_user_normalized)[1])) if x[0]==1]])\n",
    "print ('average ratings for user 0 in test after normalization: ',user_0_test_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before statring training a collaborative filter, we must set a baseline MSE as a flag to compare with. In this notebook, we are going to compute the average ratings on items given by each users in the training set and normalized the non-zero ratings in the test set by subtracting the mean. The Mean Square Error of the normalized test set is the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mse(pred, actual):\n",
    "    pred = pred[actual.nonzero()[0].tolist(),actual.nonzero()[1].tolist()].flatten()\n",
    "    actual = actual[actual.nonzero()[0].tolist(),actual.nonzero()[1].tolist()].flatten()\n",
    "    mse = mean_squared_error(pred, actual)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baseline\n",
    "def user_baseline(train,test):\n",
    "    user=0\n",
    "    item_sum=0\n",
    "    item_count=0\n",
    "    pred=np.zeros(test.shape)\n",
    "    for i in zip(np.nonzero(train)[0],np.nonzero(train)[1]):\n",
    "        if i[0]==user:\n",
    "            item_sum=train[i[0],i[1]]+item_sum\n",
    "            item_count=item_count+1\n",
    "        if i[0]>user:\n",
    "            item_pos=np.nonzero(test[user,:])[0].tolist()\n",
    "            pred[user,item_pos]=item_sum/item_count\n",
    "            user=user+1\n",
    "            item_sum=0\n",
    "            item_count=0\n",
    "            item_sum=train[i[0],i[1]]+item_sum\n",
    "            item_count=item_count+1\n",
    "    item_pos=np.nonzero(test[user,:])[0].tolist()\n",
    "    pred[user,item_pos]=item_sum/item_count\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline MSE without normalization:  1.21528380265\n"
     ]
    }
   ],
   "source": [
    "# baseline without normalization\n",
    "# baseline MSE for Stochastic Gradient Descent\n",
    "user_baseline_withoutN=user_baseline(train_Ncore_user,test_Ncore_user)\n",
    "print ('baseline MSE without normalization: ', get_mse(user_baseline_withoutN,test_Ncore_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline MSE with normalization:  1.20416387883\n"
     ]
    }
   ],
   "source": [
    "# baseline with normalization\n",
    "# baseline MSE for Alternating Least Square\n",
    "user_baseline_normalized=np.sum(test_Ncore_user_normalized**2)/len(np.nonzero(test_Ncore_user)[0])\n",
    "print ('baseline MSE with normalization: ', user_baseline_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two baseline MSE are completely same because the two normalization processes above are basically the same: when calculating the MSE without normalization, we first compute the predicted ratings in test by replacing all non-zero values in the matrix with the user-wise average of the training set, and then sum up the square difference between the actual test set and the predicted test ratings and divide the output by the number of non-zero valus in the 8-core matrix (matrix not normalized); when calculating the MSE based on normalized test set, we simply sum up the square of test set normalized by the user-wise mean in training set and divide the total number of non-zero values in the test set (8-core before normalization) as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Factorized Collaborative Filter By Alternating Least Square "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import solve\n",
    "\n",
    "class RecommendationALS():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 ratings, \n",
    "                 n_factors = 10, \n",
    "                 item_reg = 0.0, \n",
    "                 user_reg = 0.0,\n",
    "                 max_iter = 50,\n",
    "                 verbose = True):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict empty \n",
    "        entries in a matrix. The terminology assumes a \n",
    "        ratings matrix which is ~ user x item\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors to use in matrix \n",
    "            factorization model\n",
    "        \n",
    "        item_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "        \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_reg = item_reg\n",
    "        self.user_reg = user_reg\n",
    "        self._v = verbose\n",
    "        self.n_iter = max_iter\n",
    "\n",
    "    def als_step(self,\n",
    "                 latent_vectors,\n",
    "                 fixed_vecs,\n",
    "                 ratings,\n",
    "                 _lambda,\n",
    "                 type = 'user'):\n",
    "        \"\"\"\n",
    "        One of the two ALS steps. Solve for the latent vectors\n",
    "        specified by type.\n",
    "        \"\"\"\n",
    "        \n",
    "        if type == 'user':\n",
    "            # fix item vector and solve for the user vector\n",
    "            YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(YTY.shape[0]) * _lambda\n",
    "            \n",
    "            for u in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[u, :] = solve((YTY + lambdaI), ratings[u, :].dot(fixed_vecs))\n",
    "            \n",
    "            \n",
    "        elif type == 'item':\n",
    "            # fix user vector and solve for the item vector\n",
    "            XTX = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(XTX.shape[0]) * _lambda\n",
    "            \n",
    "            for i in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[i, :] = solve((XTX + lambdaI), ratings[:, i].T.dot(fixed_vecs))\n",
    "        return latent_vectors\n",
    "\n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations.\n",
    "        \"\"\"\n",
    "        ctr = 1\n",
    "        self.user_vecs = np.random.random((self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.random((self.n_items, self.n_factors))\n",
    "        \n",
    "        while ctr <= self.n_iter:\n",
    "            if ctr % 10 == 0 and self._v:\n",
    "                print ('\\tcurrent iteration: {}'.format(ctr))\n",
    "            \n",
    "            # alternative least square\n",
    "            self.user_vecs = self.als_step(self.user_vecs, \n",
    "                                           self.item_vecs, \n",
    "                                           self.ratings, \n",
    "                                           self.user_reg, \n",
    "                                           type = 'user')\n",
    "            \n",
    "            self.item_vecs = self.als_step(self.item_vecs, \n",
    "                                           self.user_vecs, \n",
    "                                           self.ratings, \n",
    "                                           self.item_reg, \n",
    "                                           type = 'item')\n",
    "            ctr += 1\n",
    "        \n",
    "        \n",
    "        return (self.user_vecs, self.item_vecs)\n",
    "    \n",
    "    def calculate_mse(self, test):\n",
    "        vecs = self.fit()\n",
    "        user_vecs = vecs[0]\n",
    "        item_vecs = vecs[1]\n",
    "        \n",
    "        predictions = np.zeros((user_vecs.shape[0], item_vecs.shape[0]))\n",
    "        for u in range(user_vecs.shape[0]):\n",
    "            for i in range(item_vecs.shape[0]):\n",
    "                predictions[u, i] = user_vecs[u, :].dot(item_vecs[i, :].T)\n",
    "                \n",
    "        self.train_mse = get_mse(predictions, self.ratings)\n",
    "        self.test_mse = get_mse(predictions, test)\n",
    "        return (self.train_mse, self.test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't add any bias terms within the __RecommendationALS__ class, we must load a normalized user-items rating matrix into the class and compute the MSE by subtracting the normalized test set from the predicted test set to correct the user bias in ratings. <br>\n",
    "_Note: Only rated items participates the computation of MSE. _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = [ RecommendationALS(ratings = train_Ncore_user_normalized, \n",
    "                  n_factors = 20,\n",
    "                  item_reg = 2.0,\n",
    "                  user_reg = 2.0,\n",
    "                  max_iter = x,\n",
    "                  verbose = False).calculate_mse(test = test_Ncore_user_normalized) for x in [10,20,30,40,50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on Training with  10  Iterations: 0.940233\n",
      "MSE on Test with  10  Iterations: 1.370528\n",
      "MSE on Training with  20  Iterations: 0.939852\n",
      "MSE on Test with  20  Iterations: 1.370582\n",
      "MSE on Training with  30  Iterations: 0.940025\n",
      "MSE on Test with  30  Iterations: 1.370567\n",
      "MSE on Training with  40  Iterations: 0.939932\n",
      "MSE on Test with  40  Iterations: 1.370647\n",
      "MSE on Training with  50  Iterations: 0.940697\n",
      "MSE on Test with  50  Iterations: 1.370585\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate([10,20,30,40,50]):\n",
    "    print (\"MSE on Training with \", v, \" Iterations: {:4.6f}\".format(out[i][0]))\n",
    "    print (\"MSE on Test with \", v, \" Iterations: {:4.6f}\".format(out[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF8JJREFUeJzt3XmYXNV55/FvtRpJbAKEHMACQZDgAGaREWG1sYWwTczj\nYZsAsQQWg5kxIJYJZGwmDuAEsPWgADIJ22SMAyYDBgOC2DFjFMB4DAaxRJYDr2TMpg0EwcKAA91S\nzR9VLUqt6upWq6qupPP9PPCo6t5T5759urp+de+5datULpeRJOWro+gCJEnFMggkKXMGgSRlziCQ\npMx1Fl3A2kopDQP+CFgCrCi4HEnaUAwBdgCejIj3a1dscEFAJQQeLboISdpAfRL4We2CDTEIlgDc\ndtttbL/99kXXIkkbhKVLlzJ58mSovobW2hCDYAXA9ttvz4477lh0LZK0oVnjkLqTxZKUOYNAkjJn\nEEhS5gwCScrchjhZPGjvvP8uS99Z1vLtlFn7C/m14+J/g6lrfVaiVHQJa6W/8e//KdB3g3Xru5/H\nNlzb33O3Wc+5gf2uS6X+2w38WTOAvgbY2cCeq/23Gd45jDFbfZSOjua+h88iCMrlMv/wzJ3884KH\nN7oXQ0l52XazbfjLT53LR0c07/T5LA4NPbdsAT9a8JAhIGmD9+Z7b3HLsz9oap9ZBMHSd94ougRJ\nappl777Z1P6yCIJ9t9uD4Z3Dii5Dkpri4J32b2p/WcwRjNp8JBd/+nz+af5slv7u9bWfZBzEnORg\nJjLX+hEDnalabRsb1gRrX9bbw3zlcsPfS3/j3+9vp2Hf/T20UYt1q2sgk7StNpATLgb+rBlAXwM8\nwWNArQbY17DOYXx8h4/xx7tPHFD7gcoiCADGbbsL5x9yetFlSNJ6J4tDQ5KkvhkEkpQ5g0CSMmcQ\nSFLmDAJJypxBIEmZMwgkKXMGgSRlziCQpMwZBJKUOYNAkjJnEEhS5gwCScqcQSBJmTMIJClzBoEk\nZc4gkKTMGQSSlDmDQJIyZxBIUuYMAknKnEEgSZkzCCQpcwaBJGXOIJCkzBkEkpS5zlZ2nlIqATcD\n8yJiRp3104AzgTLwAnBGRLzeypokSatr2R5BSmlPYDZwYh/rJwAXAodGxN7AAuCvW1WPJKm+Vh4a\nOpvK3sD3662MiKeA3SJieUppODAaeLOF9UiS6mhZEETEtIi4tZ82XSmlY4GFwOFUgkOS1EaFTxZH\nxL0RMQq4FHggpVR4TZKUk8JedFNK41JKn6hZ9B1gZ2CbgkqSpCwV+e57B+D2lNKo6v3JVM4ucp5A\nktqorUGQUjogpfQsQEQ8ClwOPFxddjJwbDvrkSS1+HMEABExteb2HGB8zf3rgetbXYMkqW9OzEpS\n5gwCScqcQSBJmTMIJClzBoEkZc4gkKTMGQSSlDmDQJIyZxBIUuYMAknKnEEgSZkzCCQpcwaBJGXO\nIJCkzBkEkpQ5g0CSMmcQSFLmDAJJypxBIEmZMwgkKXMGgSRlziCQpMwZBJKUOYNAkjJnEEhS5gwC\nScqcQSBJmTMIJClzBoEkZc4gkKTMGQSSlDmDQJIyZxBIUuYMAknKnEEgSZkzCCQpc52t7DylVAJu\nBuZFxIw666cAfw6UgfeAcyNiTitrkiStrmV7BCmlPYHZwIl9rE/AlcBRETEeuAy4u1X1SJLqa+Wh\nobOp7A18v4/17wNfjogl1ftzgO1TSkNbWJMkqZeWHRqKiGkAKaVJfax/CXip2qYEXAXcFxEftKom\nSdKaWjpHMBAppc2B7wI7AUcVW40k5afQs4ZSSmOAnwMrgIkR8dsi65GkHBW2R5BSGgk8Anw3Ir5R\nVB2SlLu2BkFK6QDg76tnCZ0JjAGOSykdV9NsUkS82c66JClnLQ+CiJhac3sOML56+3Lg8lZvX5LU\nmJ8slqTMGQSSlDmDQJIyV/jnCCRpfXPZZZfx5JNPAvDCCy8wevRohg8fDsAdd9yx6nYjs2fP5rHH\nHuPrX/96n21ee+01zjvvPG6//fbmFD5IpXK5XGgBayultAvw4uzZs9lxxx2LLkdSE/z2d+9zze1P\nM/fXb9DVvbJl29mks4N9x43i/JP3Z+sthw3oMUcccQQzZ85kn332aVld7bBw4UImTZoE8IfVKzus\n0nCPIKU0JiJe6WPdURHx46ZVKSlb19z+NE89/3rLt9PVvZKnnn+da25/mkvPOGRQfey9995MmjSJ\n559/nhkzZhAR3HHHHXR1dbF8+XLOOOMMvvjFL3L33XfzwAMPcOONN3LKKacwfvx4nn76aZYsWcKE\nCROYPn06ixcv5gtf+ALPPPMM1157LYsWLWLZsmUsWrSIkSNHcvXVV7Pddtsxd+5cLr30Urq6uhgz\nZgyLFy/ma1/7GgcddFBTxqW/OYJ7e26klH7Qa90VTalAUvaef/mtDWZ7XV1dTJw4kQceeIBdd92V\nO++8k5tuuol7772Xq6++miuvvLLu41555RVuvfVW7rvvPh5//HGeeOKJNdrMmTOHmTNn8uMf/5gR\nI0Zwxx130N3dzTnnnMN5553H/fffzymnnMJzzz036Prr6W+OoFRze9cG6yRp0PbYeZu27BHUbm9d\nHHDAAQBsvvnm3HDDDTzyyCO89NJLPP/887z33nt1HzNx4kQ6OjrYYost2HnnnVm+fPkah7cPPPBA\ntthiCwD22msvli9fzvz58wH41Kc+BcDBBx/Mbrvttk7199bfHkG5j9v17kvSoJx/8v5M2OMP2KSz\ntScybtLZwYQ9/oDzT95/nfrZbLPNAFi6dCnHHnssixYtYsKECZx//vl9PqZ2grlUKlFvfrZemyFD\nhqzRdsiQIetUf29rs0cgSS2x9ZbDBn3Mvkjz5s1j5MiRnHXWWZRKJa6//noAVqxY0bRtjB07lqFD\nh/LTn/6Uww8/nLlz5zJ//nxKpea9PPcXBB0ppW2oBMKQmtsAzY0kSdrAHHbYYdx1110cddRRbLrp\npuy7776MHDmSl19+uWnb6Ozs5Nprr+WSSy7hqquuYpdddmHUqFEDOoV1oBqePppSWknlEFC96ClH\nRNvDwNNHJeVm+vTpnH766YwaNYolS5ZwzDHH8OCDDzJixIgB9zHo00cjwk8eS1LBRo8ezdSpU+ns\n7KRcLnPZZZetVQj0p99PFle/RnJIRHSnlLYEPgPMjYhfN60KSVKfpkyZwpQpU1rWf8N3/CmlvYAX\ngaNSSpsCTwCXAQ+mlD7bsqokSW3T36GfK4G/iIh/Ak6uLtsb+CRwSSsLkyS1R39BMCYibqvengjM\nioiVEfEqsFVrS5MktUN/QVB7MuyhwE9r7jfv3CVJUmH6myz+95TSfsCWwA5UvmyelNKhwKIW1yZJ\naoP+guB/Ag9SOQz0PyLi3ZTShcBfAMe2ujhJKkIzvo+gR7lc5rTTTuPb3/52U0/5bKb+gmA+8DFg\nJbAypTQS+AWVU0h/0+LaJGVi+X+8zXVP3MK814Kuld0t284mHZ3svV3irANPZavhfb8o136ZzBFH\nHMGMGTMG/X0EK1as4LHHHhvUY9ulvzmCN4AlwGvAsur9R6icRrqstaVJysV1T9zCM0t+1dIQAOha\n2c0zS37FdU/cMug+FixYwNSpUzn++OM55phjuOeeewB45513OOecczjmmGM47rjjuPjiiymXy1x0\n0UUATJ48mddee60pP0ez9bdH8A/AYcAs4OaI+LfWlyQpN/PfaO8BhsFur6uri/POO4+rrrqKPfbY\ng7fffpsTTzyRcePGMX/+fD744ANmzZpFd3c3F198MQsXLuSb3/wm9913H7fddtuGeWgoIk5LKW0G\nHA/MTCltAdwK/GNE/LYdBUra+O0+aleeWfKrtm5vMF544QVeffVVvvrVr65a9sEHH/Dcc89x8MEH\nM3PmTE499VQOPfRQTj/9dHbaaSe6u1u7l9MM/V5iIiLeA74HfC+ltCNwCvBQSml+RJzU6gIlbfzO\nOvDUts8RDMbKlSvZeuutmTVr1qply5YtY8SIEQwbNoyf/OQn/OIXv+Dxxx/nS1/6EpdccgkTJ05s\nVvkt028Q9PKR6v+jgPZ9nZCkjdpWw0dw0eHTii6jX+PGjaOjo4Mf/vCHHH300SxatIjjjz+em266\niblz5/LLX/6S6dOnc/jhh/P666+zYMECjjzySEql0nq9ZzCQi87tBEyp/r+SyqGhgyJicYtrk6T1\nytChQ7n++uu54ooruOGGG+ju7uaCCy5gv/32Y+zYsTz55JMcffTRDB8+nNGjRzNlyhRKpRJHHnkk\nJ510EjfccANjx44t+sdYQ3/fR/AwsDtwB3BLRDzTprr65PcRSNLaG/T3EQCHA/8BfBk4PaXUs7xE\n5Ytp1s8pcEnSgPUXBH/YliokSYXp7/TR5n3xpiRpveRXUUpS5gwCScqcQSBJmTMIJClzBoEkZc4g\nkKTMre21htZKSqkE3AzMi4gZg20jSWqdlu0RpJT2BGYDJ65LG0lSa7Vyj+BsKu/0X1nHNpKkFmpZ\nEETENICU0qR1aSNJai0niyUpcwaBJGXOIJCkzLU1CFJKB6SUnm3nNiVJjbX0cwQAETG15vYcYHyj\nNpKk9vLQkCRlziCQpMwZBJKUOYNAkjJnEEhS5gwCScqcQSBJmTMIJClzBoEkZc4gkKTMGQSSlDmD\nQJIyZxBIUuYMAknKnEEgSZkzCCQpcwaBJGXOIJCkzBkEkpQ5g0CSMmcQSFLmDAJJypxBIEmZMwgk\nKXMGgSRlziCQpMwZBJKUOYNAkjJnEEhS5gwCScqcQSBJmTMIJClzBoEkZc4gkKTMGQSSlDmDQJIy\nZxBIUuY6W9l5SqkE3AzMi4gZddYfDXwTGAbMBU6PiLdbWZMkaXUt2yNIKe0JzAZO7GP9R6iExAkR\nkYDfAN9qVT2SpPpaeWjobCov9N/vY/1ngScjYkH1/vXA5OpehCSpTVp2aCgipgGklCb10WQn4NWa\n+wuBEcCWgIeHJKlNipws7mvbK9pahSRlrsggeAXYoeb+aOCtiHi3oHokKUtFBsH/BQ5OKe1Wvf8V\nYFaB9UhSltoaBCmlA1JKzwJExOvAacBdKaXngH2AC9pZjySpxZ8jAIiIqTW35wDja+7/CPhRq2uQ\nJPXNTxZLUuYMAknKnEEgSZkzCCQpcwaBJGXOIJCkzBkEkpQ5g0CSMmcQSFLmDAJJypxBIEmZMwgk\nKXMGgSRlziCQpMwZBJKUOYNAkjJnEEhS5gwCScqcQSBJmWv5dxavL15cvJz7H/0Ni994d7XlpVL1\nX0qrbteuK7Gqwap/SqU1l1G7fCD99lrY17Z6+l3Vul6/9Wqr02/tqp52a9a25rZWKTe8S7nce0nt\nuoG1W6Ntr600emjvfst93lmzn9W20+DnbLiNAeg9pKut6/3LGMBjGq0sNVjZx6YG0GeDdQ07baxc\nLlMuV34vZcpU/2Nlued2edXvbOXKcvUxvZb3tC1Xf5vl6rJ6bVf1sXrbcrVxufqY1fv4cHlPvVT7\nbNRHw7a9ltdrW9vHpsOGMGHP7Tj7hP0YPqx5L99ZBMGby3/PRdf9P979fVfRpUjSoP3uvZU8/NRC\nhnYO4ZwTxzet3ywODT0TywwBSRuNf3vxzab2l0UQfGSbTYsuQZKaZvcx2zS1vyyCYJ+xo/jcwTsX\nXYYkrZNNOjs4cK/tOePYfZrabxZzBB0dJab9yXj+9LOJJW+8++EEX7nnnw8nkeotq23fM6m4xmRj\nubxmvzXLyjUrB9Rvwzr66bfBtnomomrbNey3XF5tZnGNyWV6qW3b96o11jbqd805yAb1rE3bNZoO\nrPY1JmEHOkfaaKK7j5UNJ8cbbqvBxP3gHtbwkY0n8fvrs0RHB1A9AaIEUCrR0XOiQ6nmpIcSdJRW\nb1sqlVY7AaOnbanX41Zf3qttx+onW/Ruu+rkj9Lq213VdtXyem0/rKXe8p5lHZVOq333altdPqSj\nxJAhzX//nkUQ9Nh2q03ZdisPE0lSrSwODUmS+mYQSFLmDAJJypxBIEmZMwgkKXMb4llDQwCWLl1a\ndB2StMGoec0c0nvdhhgEOwBMnjy56DokaUO0A/BC7YINMQieBD4JLAFWFFyLJG0ohlAJgSd7ryj1\nd0lgSdLGzcliScqcQSBJmTMIJClzBoEkZc4gkKTMbYinj66VlFIJuBmYFxEzUkpDgKuAz1H5+WdE\nxA1F11VdtgxYVNPsyoi4rY01TQH+nMpF4t8DzgWeoeDxqldXRMxZD8ZrGnBmta4XgDOANyl+vNao\nKyJeL3q8auo7FrglIkasL3+Pveuq3i/6+fU3wJ8A/15dFMAXacF4bdRBkFLaE/g74GBgXnXxfwN2\nA/YGtgQeSyk9HRFPFFlXSikBb0VE876Reu1qSsCVwP4RsSSl9HngbuBbFDhefdWVUvoMxY7XBOBC\nYL+IWJ5SmgH8NfCvFDtedetKKV1FgeNVU99uwAw+PBpR+N9jvbqK/nusOhQ4OSJ+3rMgpXQWLRiv\njToIgLOpvOt+pWbZccBNEdENvJVSuh2YArTziVevrkOBFSmlh4BtgbuAyyOiXR+aex/4ckQsqd6f\nA2xP5R3JdQWOV191fZoCxysinkop7RYRXSml4cBo4EUKfn41qKvo5xcppc2A7wF/BvxjdXHhf499\n1FXoeKWUhgEfBy5MKY0Ffg38d1o0Xhv1HEFETIuIW3st3gl4teb+QmDH9lXVZ12dwE+Ao4DDqez6\nndPGml6KiB/CqsNWVwH3UfkkYmHj1aCulRQ4XtXauqqHExZWa7iZ9eP5Va+uQp9fVTdW/59bs6zw\n8aJ+XUWP10eBfwEuAsYDjwOzgDG0YLw29j2CeuqFX+GXqoiI/1Vz9/3qrvy5wDXtrCOltDnwXSp/\noEdR/51G28erd10R8dua1YWNV0TcC9ybUjoDeADortOs7eNVp65xEbGyurrt41U9pNEdEd9JKe1S\ns6rQv8e+6ir67zEiXgQ+X1PnDOAvgXrftbvO47VR7xH04RWqF66rGk0lVQuVUjolpbRvzaIS0NXm\nGsYAP6fyxJpYfbEtfLzq1VX0eKWUxqWUPlGz6DvAzlQmFwsbrwZ1Ff38mgr8UUrpWeBHwKbV2wsp\n9vlVt66U0pcKfn7tm1I6pdfiEvAILRivHPcIZgH/JaV0P7AFcDLwlWJLAiqTPyeklE4AhgLTgHae\noTCSypPsuxHxjZpVhY5Xg7oKHS8qf4z/J6U0PiLeACZTmfi/m2KfX33VtRdwXFHjFREH9tyuvvOe\nFxHjU0rnUOB4NahrOgWOF5VDn99OKf2sundwJpVDVy35e8wxCK4HxlI5u2MocGNEPFJsSQB8A/hb\n4JfAJsCdwN+3cftnUjn+eFxK6bia5Z+j2PHqq66jqZylU8h4RcSjKaXLgYdTSt3AYuBYKsdvCxuv\nBnW9RrHPr77491hHRMyrhuT91VNsFwJ/SuX32fTx8uqjkpS5HOcIJEk1DAJJypxBIEmZMwgkKXMG\ngSRlLsfTR6VVUkoHAF8DpgOnR0TTzmFPKX0ZGBoR16WUvgJsHRHfalb/UrMYBMpaRMwB/nNKaSrN\nv8bNJ6heXbaoSytLA+HnCJS1lNKngf9N5UNDWwF3R8RpKaUvAF+n8qGd94ALI+KxlNKlwCFUPsE7\nF7iAygXLtqNyVdSXgROBw6r9/h64AvgIMCoipqWUPkblw0rbUvnOgL+JiFuqtVwO/IbKJ6eHAWdH\nxEMtHgZlzjkCqfJifTHwaDUEdqPy4v35iPg48F+pfAfC5tX2O1P5foQpVD7i/1hEHALsSiU0TomI\ne6hcJfXqiPi7ng2llDqry6+NiH2BPwauSCkdUm1yEJVg+DiVILm0lT+4BAaBVM9nqLzjn129GNlt\nVK79Mq66/vHq9eCJiJnAz1NKfwZcR+Wd/BYN+t4dGB4Rd1cfvxj4AZUrvQK8HBHPVm8/DYxs2k8l\n9cE5AmlNQ4DZEXFSz4KU0k5UrvNyHPBOzfLpwIFUrvL5EJVDTKUGfdd789VRfRxU9k56lPvpS2oK\n9wikim4+fDH+F+CzKaU9AKpfjzkXGF7ncZ8Drql+0dDrVPYmhtTps0cAH6SUjq/2/VHgBCpfgiIV\nwiCQKh4D9kgp3RMRv6IyL3B7SulfqVzl9D9FxLt1HvdXwIyU0lNULkH9Mz48hPTPwLkppYt6GkdE\nF5WrgZ6XUpoLPAj8lRPCKpJnDUlS5twjkKTMGQSSlDmDQJIyZxBIUuYMAknKnEEgSZkzCCQpc/8f\nyw0S1olZnLAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ab8ed30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([10,20,30,40,50], [i[0] for i in out], \\\n",
    "             label = 'Training', linewidth=5)\n",
    "plt.plot([10,20,30,40,50], [i[1] for i in out], \\\n",
    "             label = 'Test', linewidth=5)\n",
    "\n",
    "plt.xticks(fontsize = 12);\n",
    "plt.yticks(fontsize = 12);\n",
    "plt.xlabel('iteration', fontsize = 12);\n",
    "plt.ylabel('MSE', fontsize = 12);\n",
    "plt.legend(loc = 'best', fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE on the test set is almost flat along with the increment in iterations. Thus, we select 10 iterations when tuning the number of latent factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune Number of Latent Factors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out2 = [ RecommendationALS(ratings = train_Ncore_user_normalized, \n",
    "                  n_factors = x,\n",
    "                  item_reg = 2.0,\n",
    "                  user_reg = 2.0,\n",
    "                  max_iter = 10,\n",
    "                  verbose = False).calculate_mse(test = test_Ncore_user_normalized) for x in [5,10,15,20,25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on Training with  10  Latent Factors: 0.997097\n",
      "MSE on Test with  10  Latent Factors: 1.370960\n",
      "MSE on Training with  20  Latent Factors: 0.975287\n",
      "MSE on Test with  20  Latent Factors: 1.370675\n",
      "MSE on Training with  30  Latent Factors: 0.956182\n",
      "MSE on Test with  30  Latent Factors: 1.370834\n",
      "MSE on Training with  40  Latent Factors: 0.939384\n",
      "MSE on Test with  40  Latent Factors: 1.370614\n",
      "MSE on Training with  50  Latent Factors: 0.924504\n",
      "MSE on Test with  50  Latent Factors: 1.370728\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate([10,20,30,40,50]):\n",
    "    print (\"MSE on Training with \", v, \" Latent Factors: {:4.6f}\".format(out2[i][0]))\n",
    "    print (\"MSE on Test with \", v, \" Latent Factors: {:4.6f}\".format(out2[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6rBGOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119b70f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([5,10,15,20,25], [i[0] for i in out2], \\\n",
    "             label = 'Training', linewidth=5)\n",
    "plt.plot([5,10,15,20,25], [i[1] for i in out2], \\\n",
    "             label = 'Test', linewidth=5)\n",
    "\n",
    "plt.xticks(fontsize = 12);\n",
    "plt.yticks(fontsize = 12);\n",
    "plt.xlabel('Latent Factors', fontsize = 12);\n",
    "plt.ylabel('MSE', fontsize = 12);\n",
    "plt.legend(loc = 'best', fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the two graphs above, there is no significate improvement in MSE on the test set with change in the number of latent factors and iterations. The collaborative filter with alternating least square seems having worse performance than the baseline. This output might result from two caveats: (1) the user-item ratings training matrix is highly sparse (lower than 0.2% after split), which leads to too much randomness on the baseline MSE; (2) the training set is not normalized item-wisely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Factorized Collaborative Filter By Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did three enhancement in the following Stochastic Gradient Descent Factorized Collaborative:<br>\n",
    "* Add user bias and item bias to the model\n",
    "* Apply mini-batch to updating the gradient descent\n",
    "* Add pre cut-off on the iteration when percentage change on the MSE between epoches is lower than the threshold<br>\n",
    "\n",
    "By adding user bias and item bias to the model, we re-write the loss function as\n",
    "<br>\n",
    "$$ \\sum_{u,i}{(r_{u,i}-(\\mu+b_u+b_i+x_u^{T}\\cdot y_i))^{2}}+\\lambda_{xb}\\sum_{u}\\lVert b_u\\rVert^{2}+\\lambda_{yb}\\sum_{i}\\lVert b_i\\rVert^{2}+\\lambda_{xf}\\sum_{u}\\lVert x_u\\rVert^{2}+\\lambda_{yf}\\sum_{i}\\lVert y_i\\rVert^{2}  $$  \n",
    "\n",
    "where $r_{u,i}$ is the actual ratings, $_{u}$, $_{i}$ and $_{f}$ are the number of users, items and latent factors, $ x_u$ and $y_i$ are the $_{u}$ $\\times$ $_{f}$ latent factors matrix and $_{i}$ $\\times$ $_{f}$ latent factor matrix, $b_u$ and $b_i$ are the user bias vector and the item bias vector in the length of $_{u}$ and $_{i}$ respectively, and $\\lambda_{xb}, \\lambda_{yb}, \\lambda_{xf}$ and $\\lambda_{yf} $ are the regularization terms applied on both latent factors and bias. $\\mu$ is the global bias.\n",
    "<br>\n",
    "The following is the predicted rating of a user to a specific item:\n",
    "$$\\hat{r_{u,i}}= \\mu+b_u+b_i+x_u^{T}\\cdot y_i   $$   \n",
    "\n",
    "Due to the user and item bias applied on the following model, we should load the non-normalized training data set into the Stochastic Gradient Descent Collaborative Filter and compute the MSE by subtracting the non-normalized test set from the prediction as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RecommendationSGD_Random():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 ratings, \n",
    "                 n_factors = 10, \n",
    "                 item_reg = 1.0, \n",
    "                 user_reg = 1.0,\n",
    "                 item_bias_reg = 1.0,\n",
    "                 user_bias_reg = 1.0,\n",
    "                 max_iter = 15,\n",
    "                 batch_size=3,\n",
    "                 learning_rate = 0.01,\n",
    "                 tolerance=0.0001,\n",
    "                 verbose = True):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict empty \n",
    "        entries in a matrix. The terminology assumes a \n",
    "        ratings matrix which is ~ user x item\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors to use in matrix \n",
    "            factorization model\n",
    "        \n",
    "        item_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "        \n",
    "        item_bias_reg : (float)\n",
    "            Item bias for item latent factors, shape as number of items *1\n",
    "        \n",
    "        user_bias_reg : (float)\n",
    "            User bias for user latent factors, shape as number of users *1\n",
    "            \n",
    "        max_iter: (int)\n",
    "            Max number of epoch\n",
    "        \n",
    "        batch_size: (int)\n",
    "            number of rows input each time to update the gradient\n",
    "        \n",
    "        learning_rate: (float)\n",
    "            learning rate of latent factors and bias\n",
    "        \n",
    "        tolerance: (float)\n",
    "            cut-off on iterations when percange change in loss function lower to the value\n",
    "            \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_reg = item_reg\n",
    "        self.user_reg = user_reg\n",
    "        \n",
    "        self.item_bias_reg = item_bias_reg\n",
    "        self.user_bias_reg = user_bias_reg\n",
    "        self.learning_rate = learning_rate\n",
    "        self.sample_row, self.sample_col = self.ratings.nonzero()\n",
    "        self.n_samples = len(self.sample_row)\n",
    "        self.batch_size=batch_size\n",
    "        self._v = verbose\n",
    "        self.n_iter = max_iter\n",
    "        self.MSE=[]\n",
    "        self.tolerance=0-tolerance\n",
    "\n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\" \n",
    "        Train model\n",
    "        \"\"\"       \n",
    "        self.ratings_zero=np.zeros(self.ratings.shape)\n",
    "        self.user_vecs = np.random.random((self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.random((self.n_items, self.n_factors))\n",
    "        \n",
    "        self.user_bias = np.zeros(self.n_users)\n",
    "        self.item_bias = np.zeros(self.n_items)\n",
    "        self.global_bias = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "        \n",
    "        ctr = 1\n",
    "        while ctr <= self.n_iter:\n",
    "            if ctr % 10 == 0 :\n",
    "                print ('\\tcurrent iteration: {}'.format(ctr))\n",
    "            \n",
    "            if ctr>1:\n",
    "                # predict the ratings by applying the vectorized prediction forluma\n",
    "                ratings_pred=self.user_bias[:,np.newaxis]+self.item_bias[np.newaxis,:]+self.global_bias+self.user_vecs.dot(self.item_vecs.T)\n",
    "                ratings_pred=np.nan_to_num(ratings_pred)\n",
    "                \n",
    "                self.MSE.append(get_mse(ratings_pred, self.ratings))\n",
    "                if self._v:\n",
    "                    print (self.MSE[-1])\n",
    "            if len(self.MSE)>1:\n",
    "                # set the tolerance on the difference in MSE, cut-off the iteration when the difference is less than tolerance\n",
    "                if self.MSE[-1]<self.MSE[-2] and (self.MSE[-1]-self.MSE[-2])/self.MSE[-2]>self.tolerance:\n",
    "                    return (self.user_vecs, self.item_vecs, self.user_bias, self.item_bias, self.global_bias)\n",
    "            # one sample SGD\n",
    "            self.training_indices = np.arange(self.n_samples)\n",
    "            np.random.shuffle(self.training_indices)\n",
    "            \n",
    "            for start_idx in range(0, self.n_samples - self.batch_size + 1, self.batch_size):\n",
    "                idx = self.training_indices[start_idx:start_idx + self.batch_size]\n",
    "                u = self.sample_row[idx]\n",
    "                i = self.sample_col[idx]\n",
    "                \n",
    "                # error\n",
    "                e = [self.ratings[a,b] - self.predict(a,b) for a,b in zip(u,i)]\n",
    "                \n",
    "                # update biases\n",
    "                self.user_bias[u] += self.learning_rate * (e - self.user_bias_reg * self.user_bias[u])\n",
    "                self.item_bias[i] += self.learning_rate * (e - self.item_bias_reg * self.item_bias[i])\n",
    "                \n",
    "                # update latent factors\n",
    "                self.user_vecs[u, :] = [self.user_vecs[u, :][x] + self.learning_rate * (e[x] * self.item_vecs[i, :][x] - self.user_reg * self.user_vecs[u,:][x]) for x in range(self.batch_size)]          \n",
    "                self.item_vecs[i, :] = [self.item_vecs[i, :][x] + self.learning_rate * (e[x] * self.user_vecs[u, :][x] - self.item_reg * self.item_vecs[i,:][x]) for x in range(self.batch_size)]\n",
    "                \n",
    "            ctr += 1\n",
    "        \n",
    "        \n",
    "        return (self.user_vecs, self.item_vecs, self.user_bias, self.item_bias, self.global_bias)\n",
    "    \n",
    "    def predict(self, u, i):\n",
    "        prediction = self.global_bias + self.user_bias[u] + self.item_bias[i]\n",
    "        prediction += self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "        prediction=np.nan_to_num(prediction)\n",
    "        return prediction\n",
    "    \n",
    "    def get_prediction(self):\n",
    "        vecs = self.fit()\n",
    "        user_vecs = vecs[0]\n",
    "        item_vecs = vecs[1]\n",
    "        user_bias = vecs[2]\n",
    "        item_bias = vecs[3]\n",
    "        global_bias = vecs[4]\n",
    "        predictions=user_bias[:,np.newaxis]+item_bias[np.newaxis,:]+global_bias+user_vecs.dot(item_vecs.T)\n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGD1=[RecommendationSGD_Random(train_Ncore_user,n_factors = 10,max_iter= x,\n",
    "                 batch_size=50) for x in [10,20,30,40,50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.77318169575\n",
      "1.23166861169\n",
      "1.05099926704\n",
      "0.968663731447\n",
      "0.926090870292\n",
      "0.901682136273\n",
      "0.885491408177\n",
      "0.875460417908\n",
      "\tcurrent iteration: 10\n",
      "0.868497915535\n",
      "1.78675732653\n",
      "1.23714299141\n",
      "1.05246211254\n",
      "0.969993624444\n",
      "0.926473207497\n",
      "0.901073446389\n",
      "0.88527087582\n",
      "0.875374022133\n",
      "\tcurrent iteration: 10\n",
      "0.867564929198\n",
      "0.863709322381\n",
      "0.860029999467\n",
      "0.857018663059\n",
      "0.854964009512\n",
      "0.853807175453\n",
      "0.852808713334\n",
      "0.851690287318\n",
      "0.850958029563\n",
      "0.850906683229\n",
      "1.78021895432\n",
      "1.23467447212\n",
      "1.05234223705\n",
      "0.969845817162\n",
      "0.926494795829\n",
      "0.901321971177\n",
      "0.885392695378\n",
      "0.875301075156\n",
      "\tcurrent iteration: 10\n",
      "0.868380861673\n",
      "0.863194052971\n",
      "0.859918302066\n",
      "0.85723841905\n",
      "0.85485001509\n",
      "0.853754798898\n",
      "0.852850692029\n",
      "0.851790822016\n",
      "0.850882322535\n",
      "0.850776524178\n",
      "\tcurrent iteration: 20\n",
      "0.850341684286\n",
      "0.849809598683\n",
      "0.849493321385\n",
      "0.849658042288\n",
      "0.849318148634\n",
      "0.849522283965\n",
      "0.849961441475\n",
      "0.849734018008\n",
      "0.85001650372\n",
      "0.850210806676\n",
      "\tcurrent iteration: 30\n",
      "0.84979997437\n",
      "1.79024876018\n",
      "1.24074444935\n",
      "1.05439242947\n",
      "0.971698233\n",
      "0.928389479057\n",
      "0.901930309148\n",
      "0.886286524492\n",
      "0.875617040579\n",
      "\tcurrent iteration: 10\n",
      "0.869103914396\n",
      "0.864085388815\n",
      "0.859984212015\n",
      "0.857790985013\n",
      "0.855265639499\n",
      "0.853914371521\n",
      "0.852671105692\n",
      "0.851640735121\n",
      "0.851429942061\n",
      "0.850905738906\n",
      "\tcurrent iteration: 20\n",
      "0.850870532406\n",
      "1.7874763053\n",
      "1.23846907911\n",
      "1.05401734483\n",
      "0.970874505247\n",
      "0.927322815847\n",
      "0.901402212881\n",
      "0.886430815462\n",
      "0.876373649691\n",
      "\tcurrent iteration: 10\n",
      "0.868117765629\n",
      "0.863535837375\n",
      "0.860508774724\n",
      "0.857276621998\n",
      "0.85527689775\n",
      "0.854560579533\n",
      "0.853540714499\n",
      "0.852156028751\n",
      "0.85143431299\n",
      "0.850614935811\n",
      "\tcurrent iteration: 20\n",
      "0.850320455998\n",
      "0.850009579534\n",
      "0.849987255413\n"
     ]
    }
   ],
   "source": [
    "SGD_Pred1=[x.get_prediction() for x in SGD1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on Training with  10  Iterations: 0.864009\n",
      "MSE on Test with  10  Iterations: 1.163698\n",
      "MSE on Training with  20  Iterations: 0.850907\n",
      "MSE on Test with  20  Iterations: 1.131324\n",
      "MSE on Training with  30  Iterations: 0.850256\n",
      "MSE on Test with  30  Iterations: 1.125190\n",
      "MSE on Training with  40  Iterations: 0.850871\n",
      "MSE on Test with  40  Iterations: 1.130312\n",
      "MSE on Training with  50  Iterations: 0.849987\n",
      "MSE on Test with  50  Iterations: 1.128205\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate([10,20,30,40,50]):\n",
    "    print (\"MSE on Training with \", v, \" Iterations: {:4.6f}\".format(get_mse(SGD_Pred1[i],train_Ncore_user)))\n",
    "    print (\"MSE on Test with \", v, \" Iterations: {:4.6f}\".format(get_mse(SGD_Pred1[i],test_Ncore_user)))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQkJERGIpJEREJJZCQkREYv1/ga1JtfFYORYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aa45630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([10,20,30,40,50], [get_mse(i,train_Ncore_user) for i in SGD_Pred1], \\\n",
    "             label = 'Training', linewidth=5)\n",
    "plt.plot([10,20,30,40,50], [get_mse(i,test_Ncore_user) for i in SGD_Pred1], \\\n",
    "             label = 'Test', linewidth=5)\n",
    "\n",
    "plt.xticks(fontsize = 12);\n",
    "plt.yticks(fontsize = 12);\n",
    "plt.xlabel('Iteration', fontsize = 12);\n",
    "plt.ylabel('MSE', fontsize = 12);\n",
    "plt.legend(loc = 'best', fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the number of latent factor as 10, biggest drop on MSE of the test set occurs between the epochs from 10 to 20. Although MSE reached the lowest at 30 epochs, the difference in MSEs from epoch 20 to 50 don't change too much. Besides, the trainings on Collaborative Filters with 40 and 50 epochs both expirence cut-offs after 20 more iterations. Thus, we select 20 epochs as the number of epoch to optimize both the efficiency in tuning other parameters and the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune Number of Latent Factors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGD2=[RecommendationSGD_Random(train_Ncore_user,max_iter = 20,n_factors = x,\n",
    "                 batch_size=50) for x in [5,10,20,25,30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32440332188\n",
      "1.09768500404\n",
      "1.0080939053\n",
      "0.961150281606\n",
      "0.933579204546\n",
      "0.915754976178\n",
      "0.903090342141\n",
      "0.894114981536\n",
      "\tcurrent iteration: 10\n",
      "0.887363371463\n",
      "0.882206859413\n",
      "0.878071556904\n",
      "0.875121848202\n",
      "0.872266807709\n",
      "0.870117189202\n",
      "0.86813651555\n",
      "0.866220434394\n",
      "0.864886191184\n",
      "0.863325842028\n",
      "\tcurrent iteration: 20\n",
      "0.862803307537\n",
      "1.77536520313\n",
      "1.23266415854\n",
      "1.04993403956\n",
      "0.96813749268\n",
      "0.925600360341\n",
      "0.900657710932\n",
      "0.884547784318\n",
      "0.874457147068\n",
      "\tcurrent iteration: 10\n",
      "0.867586253859\n",
      "0.862874516287\n",
      "0.859749710897\n",
      "0.856778266081\n",
      "0.854870418785\n",
      "0.853578486446\n",
      "0.852746536483\n",
      "0.851096073412\n",
      "0.851126603112\n",
      "0.850587988764\n",
      "\tcurrent iteration: 20\n",
      "0.850552892644\n",
      "2.74020608834\n",
      "1.47987919306\n",
      "1.11903605554\n",
      "0.975692677093\n",
      "0.907887406033\n",
      "0.873346778096\n",
      "0.8533230513\n",
      "0.841845133944\n",
      "\tcurrent iteration: 10\n",
      "0.835380073211\n",
      "0.831044519369\n",
      "0.828597246446\n",
      "0.826931451391\n",
      "0.826666711847\n",
      "0.826215355786\n",
      "0.82648612773\n",
      "0.826624379116\n",
      "0.827491036776\n",
      "0.828625639077\n",
      "\tcurrent iteration: 20\n",
      "0.829278487611\n",
      "3.17124716999\n",
      "1.57466386011\n",
      "1.14072438901\n",
      "0.973487927513\n",
      "0.897389440266\n",
      "0.859652362614\n",
      "0.838727193714\n",
      "0.827572811976\n",
      "\tcurrent iteration: 10\n",
      "0.82094777187\n",
      "0.816764092935\n",
      "0.815568142517\n",
      "0.815119400373\n",
      "0.814720226139\n",
      "0.814997715404\n",
      "0.815441647664\n",
      "0.817120238447\n",
      "0.817371354754\n",
      "0.818577901558\n",
      "\tcurrent iteration: 20\n",
      "0.819995014928\n",
      "3.53898094375\n",
      "1.64043618285\n",
      "1.14675923969\n",
      "0.963615351143\n",
      "0.88323428767\n",
      "0.843316806524\n",
      "0.822794809342\n",
      "0.811409876957\n",
      "\tcurrent iteration: 10\n",
      "0.805022159734\n",
      "0.802633478061\n",
      "0.801048667573\n",
      "0.801595214356\n",
      "0.801772653568\n",
      "0.803015890661\n",
      "0.804916478725\n",
      "0.805994929079\n",
      "0.808052231374\n",
      "0.809444865833\n",
      "\tcurrent iteration: 20\n",
      "0.810937307791\n"
     ]
    }
   ],
   "source": [
    "SGD_Pred2=[x.get_prediction() for x in SGD2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on Training with  5  Latent Factors:  0.861936460172\n",
      "MSE on Test with  5  Latent Factors:  1.12752300633\n",
      "MSE on Training with  10  Latent Factors:  0.850552892644\n",
      "MSE on Test with  10  Latent Factors:  1.13191113069\n",
      "MSE on Training with  20  Latent Factors:  0.829780465649\n",
      "MSE on Test with  20  Latent Factors:  1.14893670239\n",
      "MSE on Training with  25  Latent Factors:  0.821514888452\n",
      "MSE on Test with  25  Latent Factors:  1.15673135994\n",
      "MSE on Training with  30  Latent Factors:  0.812650501339\n",
      "MSE on Test with  30  Latent Factors:  1.16749595385\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate([5,10,20,25,30]):\n",
    "    print (\"MSE on Training with \", v, \" Latent Factors: \",get_mse(SGD_Pred2[i],train_Ncore_user))\n",
    "    print (\"MSE on Test with \", v, \" Latent Factors: \",get_mse(SGD_Pred2[i],test_Ncore_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuIGCDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a2b6be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([5,10,20,25,30], [get_mse(i,train_Ncore_user) for i in SGD_Pred2], \\\n",
    "             label = 'Training', linewidth=5)\n",
    "plt.plot([5,10,20,25,30], [get_mse(i,test_Ncore_user) for i in SGD_Pred2], \\\n",
    "             label = 'Test', linewidth=5)\n",
    "\n",
    "plt.xticks(fontsize = 12);\n",
    "plt.yticks(fontsize = 12);\n",
    "plt.xlabel('latent factor', fontsize = 12);\n",
    "plt.ylabel('MSE', fontsize = 12);\n",
    "plt.legend(loc = 'best', fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under 20 epoches for each combination of N factors, the model overfits the training set along with the increase in number of factors. Thus, 5 latent factors are selected since the MSE of the test set reaches the lowest at this point.<br>\n",
    "The MSE of the Latenet Factorized Collaborative Filter trainied by Stochastic Gradient Descent is obvisouly lower than the baseline. We will recommend top N ranked items by the predicted ratings from this filter in the following recommendation system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcurrent iteration: 10\n",
      "\tcurrent iteration: 20\n"
     ]
    }
   ],
   "source": [
    "SGD2=[RecommendationSGD_Random(train_Ncore_user,max_iter = 20,n_factors = x,\n",
    "                 batch_size=50,verbose=False) for x in [5]]\n",
    "SGD_Pred2=[x.get_prediction() for x in SGD2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1211664005270885"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mse(SGD_Pred2[0],test_Ncore_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation With Item Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate prediction of the collaborative filter really make sense or not, we decide to check the output in a more intuitive way by comparing what the system recommended with what the user's already rated. For this comparison, information other than asin (product ID) such as item name, description on the item and the category where the item belongs to is required.<br>\n",
    "These information is stored in __meta_Beauty.json__. In the recommendation system, the asin of the top recommended items are linked back to the meta data to extract those details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read-In Product Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_original = getDF('meta_Beauty.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta=copy.deepcopy(meta_original)\n",
    "for i in range(4):\n",
    "    meta['type_L'+str(i)] = meta['categories'].apply(lambda x: x[0][i] if i<len(x[0]) else np.nan)\n",
    "item_category=pd.DataFrame(meta.groupby(['type_L0', 'type_L1', 'type_L2', 'type_L3'])['asin'].nunique()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['imUrl', 'description', 'asin', 'salesRank', 'title', 'categories',\n",
       "       'price', 'related', 'brand', 'type_L0', 'type_L1', 'type_L2',\n",
       "       'type_L3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_L0</th>\n",
       "      <th>type_L1</th>\n",
       "      <th>type_L2</th>\n",
       "      <th>type_L3</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"53\" valign=\"top\">Beauty</th>\n",
       "      <th rowspan=\"18\" valign=\"top\">Bath &amp; Body</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">Bath</th>\n",
       "      <th>Bath Bombs</th>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bath Pearls &amp; Flakes</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bubble Bath</th>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minerals &amp; Salts</th>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oils</th>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tub Tea</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Bathing Accessories</th>\n",
       "      <th>Bath Brushes</th>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bath Mitts &amp; Cloths</th>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bath Pillows</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bath Trays</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eye Masks</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loofahs, Sponges &amp; Poufs</th>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shower Caps</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Cleansers</th>\n",
       "      <th>Body Washes</th>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soaps</th>\n",
       "      <td>6238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Scrubs &amp; Body Treatments</th>\n",
       "      <th>Body Mud</th>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Body Scrubs</th>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Body Souffles &amp; Mousse</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Fragrance</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Men's</th>\n",
       "      <th>Cologne</th>\n",
       "      <td>1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eau de Parfum</th>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eau de Toilette</th>\n",
       "      <td>3567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sets</th>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Women's</th>\n",
       "      <th>Body Sprays</th>\n",
       "      <td>1153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cologne</th>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eau de Parfum</th>\n",
       "      <td>7523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eau de Toilette</th>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Essential Oils</th>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sets</th>\n",
       "      <td>2098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Hair Care</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Hair Color</th>\n",
       "      <th>Chemical Hair Dyes</th>\n",
       "      <td>3438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color Correctors</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"22\" valign=\"top\">Tools &amp; Accessories</th>\n",
       "      <th>Hair Coloring Tools</th>\n",
       "      <th>Hair Color Removers</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Makeup Brushes &amp; Tools</th>\n",
       "      <th>Blotting Paper</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brushes &amp; Applicators</th>\n",
       "      <td>2545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eyelash Tools</th>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puffs, Sponges &amp; Wedges</th>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sets &amp; Kits</th>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpeners</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Treatment Tools</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Mirrors</th>\n",
       "      <th>Makeup Mirrors</th>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shower Mirrors</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Nail Tools</th>\n",
       "      <th>Clippers &amp; Trimmers</th>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cuticle Pushers</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cuticle Scissors</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Nails</th>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foot Rasps</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nail Art Equipment</th>\n",
       "      <td>1670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nail Brushes</th>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nail Dryers</th>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nail Files &amp; Buffers</th>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sets &amp; Kits</th>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spa Slippers</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toe Separators</th>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Health &amp; Personal Care</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Pain Relievers</th>\n",
       "      <th>Hot &amp; Cold Therapies</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Household Supplies</th>\n",
       "      <th>Household Cleaning</th>\n",
       "      <th>All-Purpose Cleaners</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Personal Care</th>\n",
       "      <th>Deodorants &amp; Antiperspirants</th>\n",
       "      <th>Men's Deodorants &amp; Antiperspirants</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lip Care</th>\n",
       "      <th>Balms &amp; Moisturizers</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Stationery &amp; Party Supplies</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Party Supplies</th>\n",
       "      <th>Decorations</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Favors</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home &amp; Kitchen</th>\n",
       "      <th>Kitchen &amp; Dining</th>\n",
       "      <th>Home Brewing &amp; Wine Making</th>\n",
       "      <th>Beer Brewing</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports &amp; Outdoors</th>\n",
       "      <th>Fan Shop</th>\n",
       "      <th>Bags, Packs &amp; Accessories</th>\n",
       "      <th>Tote Bags</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    asin\n",
       "type_L0                type_L1                     type_L2                      type_L3                                 \n",
       "Beauty                 Bath & Body                 Bath                         Bath Bombs                           254\n",
       "                                                                                Bath Pearls & Flakes                  33\n",
       "                                                                                Bubble Bath                          516\n",
       "                                                                                Minerals & Salts                     791\n",
       "                                                                                Oils                                 295\n",
       "                                                                                Tub Tea                               26\n",
       "                                                   Bathing Accessories          Bath Brushes                         301\n",
       "                                                                                Bath Mitts & Cloths                  296\n",
       "                                                                                Bath Pillows                         177\n",
       "                                                                                Bath Trays                            69\n",
       "                                                                                Eye Masks                             52\n",
       "                                                                                Loofahs, Sponges & Poufs             597\n",
       "                                                                                Shower Caps                          403\n",
       "                                                   Cleansers                    Body Washes                         4918\n",
       "                                                                                Soaps                               6238\n",
       "                                                   Scrubs & Body Treatments     Body Mud                             219\n",
       "                                                                                Body Scrubs                         3340\n",
       "                                                                                Body Souffles & Mousse               149\n",
       "                       Fragrance                   Men's                        Cologne                             1763\n",
       "                                                                                Eau de Parfum                        304\n",
       "                                                                                Eau de Toilette                     3567\n",
       "                                                                                Sets                                1105\n",
       "                                                   Women's                      Body Sprays                         1153\n",
       "                                                                                Cologne                              925\n",
       "                                                                                Eau de Parfum                       7523\n",
       "                                                                                Eau de Toilette                     4480\n",
       "                                                                                Essential Oils                       674\n",
       "                                                                                Sets                                2098\n",
       "                       Hair Care                   Hair Color                   Chemical Hair Dyes                  3438\n",
       "                                                                                Color Correctors                      75\n",
       "...                                                                                                                  ...\n",
       "                       Tools & Accessories         Hair Coloring Tools          Hair Color Removers                   31\n",
       "                                                   Makeup Brushes & Tools       Blotting Paper                       121\n",
       "                                                                                Brushes & Applicators               2545\n",
       "                                                                                Eyelash Tools                       1956\n",
       "                                                                                Puffs, Sponges & Wedges              315\n",
       "                                                                                Sets & Kits                          593\n",
       "                                                                                Sharpeners                            80\n",
       "                                                                                Treatment Tools                      331\n",
       "                                                   Mirrors                      Makeup Mirrors                      1252\n",
       "                                                                                Shower Mirrors                        78\n",
       "                                                   Nail Tools                   Clippers & Trimmers                  726\n",
       "                                                                                Cuticle Pushers                      117\n",
       "                                                                                Cuticle Scissors                     139\n",
       "                                                                                False Nails                         1196\n",
       "                                                                                Foot Rasps                           153\n",
       "                                                                                Nail Art Equipment                  1670\n",
       "                                                                                Nail Brushes                         351\n",
       "                                                                                Nail Dryers                          355\n",
       "                                                                                Nail Files & Buffers                 919\n",
       "                                                                                Sets & Kits                         1025\n",
       "                                                                                Spa Slippers                         245\n",
       "                                                                                Toe Separators                       181\n",
       "Health & Personal Care Health Care                 Pain Relievers               Hot & Cold Therapies                   1\n",
       "                       Household Supplies          Household Cleaning           All-Purpose Cleaners                   1\n",
       "                       Personal Care               Deodorants & Antiperspirants Men's Deodorants & Antiperspirants     1\n",
       "                                                   Lip Care                     Balms & Moisturizers                   1\n",
       "                       Stationery & Party Supplies Party Supplies               Decorations                            1\n",
       "                                                                                Favors                                 1\n",
       "Home & Kitchen         Kitchen & Dining            Home Brewing & Wine Making   Beer Brewing                           1\n",
       "Sports & Outdoors      Fan Shop                    Bags, Packs & Accessories    Tote Bags                              1\n",
       "\n",
       "[172 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.groupby(['type_L0', 'type_L1', 'type_L2', 'type_L3']).asin.nunique().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the table above, a three-layer category has been sufficient for us to understand the purpose of a product. Those three categories would be presented in the following function telling what kind of product the user has rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Advanced_Recommendation(Pred,ratings_Ncore,User,N):\n",
    "    user_in_list=user_map_afterNcore.ix[user_map_afterNcore['reviewerID']==User,'reviewerID_Ncore']\n",
    "    if pd.notnull(user_in_list.values[0]):\n",
    "        Pred_C=copy.deepcopy(Pred)\n",
    "        #replace all the item rated by users as zero to avoid recommend item user already bought\n",
    "        Pred_C[np.where(ratings_Ncore!=0)[0],np.where(ratings_Ncore!=0)[1]]=0\n",
    "        #find what the user has rated\n",
    "        item_bought=np.nonzero(ratings_Ncore[int(user_in_list.values[0]),:])[0].tolist()\n",
    "        asin_bought=item_map_afterNcore.loc[item_map_afterNcore['asinID_Ncore'].isin(item_bought),'asin'].tolist()\n",
    "        category_bought=meta.loc[meta['asin'].isin(asin_bought),['type_L1','type_L2','type_L3','asin']]\n",
    "        category_bought_df=category_bought.groupby(['type_L1','type_L2','type_L3'])['asin'].nunique().to_frame().reset_index()\\\n",
    "        .sort_values(by='asin',ascending=False)\n",
    "        total=np.sum(category_bought_df['asin'])\n",
    "        category_bought_df['precent']=category_bought_df['asin']/total\n",
    "        category_bought_df['precent']=category_bought_df['precent'].apply(lambda x: \"{0:.0%}\".format(x))\n",
    "        print ('items bought')\n",
    "        print(category_bought_df[['type_L1','type_L2','type_L3','asin','precent']])\n",
    "        #recommend items\n",
    "        item_Ncore=np.argsort(Pred_C[int(user_in_list.values[0]),:])[:-N-1:-1].tolist()\n",
    "        Recommend=item_map_afterNcore.loc[item_map_afterNcore['asinID_Ncore'].isin(item_Ncore),'asin'].tolist()\n",
    "        print (\"\\n items recommended\")\n",
    "        return  meta.loc[meta['asin'].isin(Recommend),['asin','title','type_L1','type_L2','type_L3','description','imUrl']]\n",
    "    else:\n",
    "        print ('Too few items bought to predict')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select reviewer 'AZXP46IB63PU8' to predict what top ten items the system recommends and compare with items he/she rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items bought\n",
      "       type_L1 type_L2                type_L3  asin precent\n",
      "2    Skin Care    Face  Creams & Moisturizers     4     50%\n",
      "1    Skin Care    Body           Moisturizers     2     25%\n",
      "0  Bath & Body    Bath            Bubble Bath     1     12%\n",
      "3    Skin Care    Face          Oils & Serums     1     12%\n",
      "\n",
      " items recommended\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>type_L1</th>\n",
       "      <th>type_L2</th>\n",
       "      <th>type_L3</th>\n",
       "      <th>description</th>\n",
       "      <th>imUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>B00027CGWQ</td>\n",
       "      <td>Udderly Smooth Udder Cream, Skin Moisturizer, ...</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Body</td>\n",
       "      <td>Moisturizers</td>\n",
       "      <td>Udderly  SMooth Udder Cream is a water-based m...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51fm2Lcc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16778</th>\n",
       "      <td>B000F8FZAC</td>\n",
       "      <td>Moisturizer-Almond Aloe With SPF15 Earth Scien...</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Creams &amp; Moisturizers</td>\n",
       "      <td>Moisturizer-Almond Aloe With SPF15 by Earth Sc...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31lPlx89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16946</th>\n",
       "      <td>B000FCNW26</td>\n",
       "      <td>Obsession Night by Calvin Klein for Women, Eau...</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Women's</td>\n",
       "      <td>Eau de Parfum</td>\n",
       "      <td>Obsession Night by Calvin Klein designer fragr...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41noHh7L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77207</th>\n",
       "      <td>B002BPY7H4</td>\n",
       "      <td>Doo Gro Stimulating Growth Oil</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Body</td>\n",
       "      <td>Moisturizers</td>\n",
       "      <td>Doo Gro Stimulating Growth Oil promotes strong...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31f1rOgN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78633</th>\n",
       "      <td>B002E788WE</td>\n",
       "      <td>PedEgg Original Foot File</td>\n",
       "      <td>Tools &amp; Accessories</td>\n",
       "      <td>Nail Tools</td>\n",
       "      <td>Foot Rasps</td>\n",
       "      <td>As seen on TV. Gently removes callous, dry ski...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41y7NRKu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100230</th>\n",
       "      <td>B003H87S0C</td>\n",
       "      <td>Dr. Dennis Gross Skincare Original Formula Alp...</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Treatments &amp; Masks</td>\n",
       "      <td>Specifically proven results can only be achiev...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41E4YoTR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100260</th>\n",
       "      <td>B003HD04DK</td>\n",
       "      <td>Formula 10.0.6 Totally Clean Cleanser Original...</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Treatments &amp; Masks</td>\n",
       "      <td>Formula 10.0.6 Totally Clean Cleanser Original...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31TlfovW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103444</th>\n",
       "      <td>B003MTPE5M</td>\n",
       "      <td>Gratiae Organics Ultrox Expression Marks Anti ...</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Creams &amp; Moisturizers</td>\n",
       "      <td>The GRATiAE Organic Ultrox Expression Marks An...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41iJrrxo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117230</th>\n",
       "      <td>B004A7VG70</td>\n",
       "      <td>Olay Cleansing Body Wash, Silky Berry, 23.6 Fl...</td>\n",
       "      <td>Bath &amp; Body</td>\n",
       "      <td>Cleansers</td>\n",
       "      <td>Body Washes</td>\n",
       "      <td></td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/412Zmdgj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201912</th>\n",
       "      <td>B00A7FS2OO</td>\n",
       "      <td>DNS Biogenesis Eye Roller-vessel Sealing Syste...</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Eyes</td>\n",
       "      <td>Rollers &amp; Pens</td>\n",
       "      <td>At bioGenesis London, our skin scientists are ...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41qhgSgh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin                                              title  \\\n",
       "5168    B00027CGWQ  Udderly Smooth Udder Cream, Skin Moisturizer, ...   \n",
       "16778   B000F8FZAC  Moisturizer-Almond Aloe With SPF15 Earth Scien...   \n",
       "16946   B000FCNW26  Obsession Night by Calvin Klein for Women, Eau...   \n",
       "77207   B002BPY7H4                     Doo Gro Stimulating Growth Oil   \n",
       "78633   B002E788WE                          PedEgg Original Foot File   \n",
       "100230  B003H87S0C  Dr. Dennis Gross Skincare Original Formula Alp...   \n",
       "100260  B003HD04DK  Formula 10.0.6 Totally Clean Cleanser Original...   \n",
       "103444  B003MTPE5M  Gratiae Organics Ultrox Expression Marks Anti ...   \n",
       "117230  B004A7VG70  Olay Cleansing Body Wash, Silky Berry, 23.6 Fl...   \n",
       "201912  B00A7FS2OO  DNS Biogenesis Eye Roller-vessel Sealing Syste...   \n",
       "\n",
       "                    type_L1     type_L2                type_L3  \\\n",
       "5168              Skin Care        Body           Moisturizers   \n",
       "16778             Skin Care        Face  Creams & Moisturizers   \n",
       "16946             Fragrance     Women's          Eau de Parfum   \n",
       "77207             Skin Care        Body           Moisturizers   \n",
       "78633   Tools & Accessories  Nail Tools             Foot Rasps   \n",
       "100230            Skin Care        Face     Treatments & Masks   \n",
       "100260            Skin Care        Face     Treatments & Masks   \n",
       "103444            Skin Care        Face  Creams & Moisturizers   \n",
       "117230          Bath & Body   Cleansers            Body Washes   \n",
       "201912            Skin Care        Eyes         Rollers & Pens   \n",
       "\n",
       "                                              description  \\\n",
       "5168    Udderly  SMooth Udder Cream is a water-based m...   \n",
       "16778   Moisturizer-Almond Aloe With SPF15 by Earth Sc...   \n",
       "16946   Obsession Night by Calvin Klein designer fragr...   \n",
       "77207   Doo Gro Stimulating Growth Oil promotes strong...   \n",
       "78633   As seen on TV. Gently removes callous, dry ski...   \n",
       "100230  Specifically proven results can only be achiev...   \n",
       "100260  Formula 10.0.6 Totally Clean Cleanser Original...   \n",
       "103444  The GRATiAE Organic Ultrox Expression Marks An...   \n",
       "117230                                                      \n",
       "201912  At bioGenesis London, our skin scientists are ...   \n",
       "\n",
       "                                                    imUrl  \n",
       "5168    http://ecx.images-amazon.com/images/I/51fm2Lcc...  \n",
       "16778   http://ecx.images-amazon.com/images/I/31lPlx89...  \n",
       "16946   http://ecx.images-amazon.com/images/I/41noHh7L...  \n",
       "77207   http://ecx.images-amazon.com/images/I/31f1rOgN...  \n",
       "78633   http://ecx.images-amazon.com/images/I/41y7NRKu...  \n",
       "100230  http://ecx.images-amazon.com/images/I/41E4YoTR...  \n",
       "100260  http://ecx.images-amazon.com/images/I/31TlfovW...  \n",
       "103444  http://ecx.images-amazon.com/images/I/41iJrrxo...  \n",
       "117230  http://ecx.images-amazon.com/images/I/412Zmdgj...  \n",
       "201912  http://ecx.images-amazon.com/images/I/41qhgSgh...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Advanced_Recommendation(SGD_Pred2[0],ratings_Ncore,User='AZXP46IB63PU8',N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>title</th>\n",
       "      <th>type_L1</th>\n",
       "      <th>type_L2</th>\n",
       "      <th>type_L3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I did 't have a reaction to this cream which i...</td>\n",
       "      <td>AZXP46IB63PU8</td>\n",
       "      <td>B0007W1R58</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Olay Regenerist Night Recovery Cream 1.7 Oz</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Body</td>\n",
       "      <td>Moisturizers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased this because I bought the day crea...</td>\n",
       "      <td>AZXP46IB63PU8</td>\n",
       "      <td>B000KPO99I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>L'Oreal Paris Age Perfect Night Cream, 2.5 Flu...</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Creams &amp; Moisturizers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I use this every day.  It's a light face cream...</td>\n",
       "      <td>AZXP46IB63PU8</td>\n",
       "      <td>B000UVZU1S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>St. Ives Facial Moisturizer, Timeless Skin Col...</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Creams &amp; Moisturizers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My face is very dry and flakey.  This cream ke...</td>\n",
       "      <td>AZXP46IB63PU8</td>\n",
       "      <td>B0012J30LY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Regenerist Micro-Sculpting Cream 1.7 Oz</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Creams &amp; Moisturizers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have diabetic never pain and was looking for...</td>\n",
       "      <td>AZXP46IB63PU8</td>\n",
       "      <td>B0043494XS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Conair Waterfall Foot Spa with Lights, Bubbles...</td>\n",
       "      <td>Bath &amp; Body</td>\n",
       "      <td>Bath</td>\n",
       "      <td>Bubble Bath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Really great skin cream.  I bought it because ...</td>\n",
       "      <td>AZXP46IB63PU8</td>\n",
       "      <td>B004YWRYUY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>L'oreal Age Perfect Day Cream SPF 15 2.5 Oz</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Creams &amp; Moisturizers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A really great skin fluid.  I like it even mor...</td>\n",
       "      <td>AZXP46IB63PU8</td>\n",
       "      <td>B005H1541C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>L'Oreal Paris Age Perfect Hydra-Nutrition Adva...</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Oils &amp; Serums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If you have dry skin for whatever reason, this...</td>\n",
       "      <td>AZXP46IB63PU8</td>\n",
       "      <td>B00AHH00TC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gold Bond Diabetic Skin Relief Lotion, 13 Ounce</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Body</td>\n",
       "      <td>Moisturizers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText     reviewerID  \\\n",
       "0  I did 't have a reaction to this cream which i...  AZXP46IB63PU8   \n",
       "1  I purchased this because I bought the day crea...  AZXP46IB63PU8   \n",
       "2  I use this every day.  It's a light face cream...  AZXP46IB63PU8   \n",
       "3  My face is very dry and flakey.  This cream ke...  AZXP46IB63PU8   \n",
       "4  I have diabetic never pain and was looking for...  AZXP46IB63PU8   \n",
       "5  Really great skin cream.  I bought it because ...  AZXP46IB63PU8   \n",
       "6  A really great skin fluid.  I like it even mor...  AZXP46IB63PU8   \n",
       "7  If you have dry skin for whatever reason, this...  AZXP46IB63PU8   \n",
       "\n",
       "         asin  overall                                              title  \\\n",
       "0  B0007W1R58      5.0        Olay Regenerist Night Recovery Cream 1.7 Oz   \n",
       "1  B000KPO99I      5.0  L'Oreal Paris Age Perfect Night Cream, 2.5 Flu...   \n",
       "2  B000UVZU1S      5.0  St. Ives Facial Moisturizer, Timeless Skin Col...   \n",
       "3  B0012J30LY      5.0            Regenerist Micro-Sculpting Cream 1.7 Oz   \n",
       "4  B0043494XS      5.0  Conair Waterfall Foot Spa with Lights, Bubbles...   \n",
       "5  B004YWRYUY      5.0        L'oreal Age Perfect Day Cream SPF 15 2.5 Oz   \n",
       "6  B005H1541C      5.0  L'Oreal Paris Age Perfect Hydra-Nutrition Adva...   \n",
       "7  B00AHH00TC      5.0    Gold Bond Diabetic Skin Relief Lotion, 13 Ounce   \n",
       "\n",
       "       type_L1 type_L2                type_L3  \n",
       "0    Skin Care    Body           Moisturizers  \n",
       "1    Skin Care    Face  Creams & Moisturizers  \n",
       "2    Skin Care    Face  Creams & Moisturizers  \n",
       "3    Skin Care    Face  Creams & Moisturizers  \n",
       "4  Bath & Body    Bath            Bubble Bath  \n",
       "5    Skin Care    Face  Creams & Moisturizers  \n",
       "6    Skin Care    Face          Oils & Serums  \n",
       "7    Skin Care    Body           Moisturizers  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the details about what the user has rated\n",
    "df.loc[df['reviewerID']=='AZXP46IB63PU8'].merge(meta, how='left',on='asin')[[\"reviewText\",\"reviewerID\",\\\n",
    "                                                                             \"asin\",\"overall\",\"title\",\\\n",
    "                                                                             \"type_L1\",\"type_L2\",\"type_L3\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the table above, most items this user rated are anti-aging products, which indicates his/her age might be over fourty fifty. He/She also bought foot care, which indicates this user might be focus on detail parts of his/her body.<br>\n",
    "Anti-wrinkle and anti-oxidants products with asin ID as \"B003MTPE5M\" and \"B003H87S0C\" are amongst the top 10 items recommended to the customer. These items are most related to the anti-aging products the customer cares about. Besides, this customer has a dry skin according to his/her reviews. The body wash product 'B004A7VG70' also provide extra moisture to skin.<br>\n",
    "<br/>\n",
    "___Note___: Since the collborative filter recommends products to customer bought at least 8 items and pops out 3 items rated by each customer into test set at the beginning, there is much more randomness in the recommended items to customers who rated few number of items. For instance, the customer analyzed above rated 6 anti-aging products and 2 others. With the random split on the item rated into training and test, the combination of 5 anti-aging products in the training set versus the combination of 3 anti-aging products and 2 other products would lead to a very different prediction for this customer. The randomness in recommended items is derived from the high sparsity of the overall user-item rating matrix. And, too many sample would be dropped if we take an aggressive lift the threshold on number of items rated by users in the N-core matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Moisturizer-Almond Aloe With SPF15 Earth Science 5 oz Cream']], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta['asin']==\"B000F8FZAC\",[\"title\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
